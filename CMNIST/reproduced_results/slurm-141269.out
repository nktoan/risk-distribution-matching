./.conda/envs/domainbed/bin/python
./source_code_conf/risk-distribution-matching/CMNIST
./causal_optimisation_dg/quantile_rm/DomainBed/domainbed/data/
Args:
	algorithm: rdm
	alpha: -10000
	batch_size: 25000
	data_dir: ./causal_optimisation_dg/quantile_rm/DomainBed/domainbed/data/
	deterministic: False
	dropout_p: 0.2
	erm_pretrain_iters: 0
	eval_freq: 50
	exp_name: reproduce
	full_resolution: False
	groupdro_eta: 1.0
	loss_fn: nll
	lr: 0.0001
	lr_cos_sched: True
	lr_factor_reduction: 1
	mlp_hidden_dim: 390
	n_workers: 0
	network: MLP
	output_dir: ./source_code_conf/risk-distribution-matching/CMNIST
	penalty_weight: 10000.0
	save_ckpts: True
	seed: 0
	steps: 600
	test_env_ms: 0.9
	test_envs: 0.1,0.2,0.5,0.9
	train_env_ps: (0.1, 0.2)
	train_envs: default
	variance_weight: 0.005
	weight_decay: 0
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.5929000000  0.6804077625  0.5754000000  0.6832284331  0.5461000000  0.6886765361  0.4857000000  0.6970292926  0.4973566389  50.000000000  0.6848430634  0.0000687242  0.0000002359  0.7212800980  50            0.0078828074 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.6292000000  0.6678779721  0.6132000000  0.6725376844  0.5667000000  0.6814895272  0.5021000000  0.6952251196  0.2294584751  100.00000000  0.6748661995  0.0000675302  0.0000000366  0.7212800980  100           0.0140795717 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.6816000000  0.6466307044  0.6544000000  0.6551405191  0.5963000000  0.6739485860  0.5075000000  0.7005047798  0.1530950626  150.00000000  0.6530809402  0.0000683221  0.0000030021  0.7212800980  150           0.0238504559 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.7038000000  0.6291109920  0.6754000000  0.6405043006  0.6156000000  0.6673078537  0.5250000000  0.7038781047  0.1147850609  200.00000000  0.6434164047  0.0000645242  0.0000001648  0.7212800980  200           0.0355043560 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.6774000000  0.6319844127  0.6599000000  0.6411412954  0.6261000000  0.6611464024  0.5756000000  0.6887319684  0.0918807898  250.00000000  0.6411438584  0.0000645801  0.0000004405  0.7212800980  250           0.0504467338 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.7303000000  0.5970820189  0.6967000000  0.6163657904  0.6157000000  0.6617150903  0.4984000000  0.7245125771  0.0767805648  300.00000000  0.6186551452  0.0000623277  0.0000004316  0.7212800980  300           0.0610869154 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.7043000000  0.6066612005  0.6777000000  0.6229076982  0.6189000000  0.6584972739  0.5328000000  0.7091575265  0.0651531124  350.00000000  0.6221737862  0.0000626218  0.0000003685  0.7212800980  350           0.0717875212 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.7006000000  0.6097473502  0.6794000000  0.6240440011  0.6288000000  0.6560651064  0.5560000000  0.7005148530  0.0552428240  400.00000000  0.6238222122  0.0000659141  0.0000034960  0.7212800980  400           0.0716748908 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.7170000000  0.5978997946  0.6918000000  0.6152709126  0.6264000000  0.6564427018  0.5388000000  0.7124832869  0.0489795150  450.00000000  0.6156979799  0.0000631045  0.0000014982  0.7212800980  450           0.0729926825 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.7176000000  0.5954508781  0.6925000000  0.6137071252  0.6252000000  0.6563040018  0.5332000000  0.7149088979  0.0441613488  500.00000000  0.6113686562  0.0000636684  0.0000024937  0.7212800980  500           0.0757588968 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.7143000000  0.5972509384  0.6892000000  0.6149464846  0.6261000000  0.6558851600  0.5400000000  0.7123267651  0.0400889579  550.00000000  0.6161628962  0.0000617344  0.0000000789  0.7212800980  550           0.0785085857 
0.1_acc       0.1_loss      0.2_acc       0.2_loss      0.5_acc       0.5_loss      0.9_acc       0.9_loss      avg_step_tim  epoch         erm_loss      loss          matching_pen  mem_gb        step          variance_pen 
0.7145000000  0.5971617103  0.6896000000  0.6148638725  0.6258000000  0.6558592916  0.5395000000  0.7123441696  0.0368506845  600.00000000  0.6129126549  0.0000613985  0.0000000688  0.7212800980  600           0.0768462867 

final accuracies:
0.0    0.1    0.2    0.3    0.4    0.5    0.6    0.7    0.8    0.9    1.0   
0.739  0.714  0.701  0.669  0.657  0.624  0.604  0.597  0.575  0.542  0.524 

best accuracies:
0.0    0.1    0.2    0.3    0.4    0.5    0.6    0.7    0.8    0.9    1.0   
0.686  0.672  0.668  0.647  0.641  0.625  0.611  0.614  0.600  0.575  0.572 
