Environment:
	Python: 3.11.2
	PyTorch: 2.0.0+cu117
	Torchvision: 0.15.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.2
	PIL: 9.5.0
Args:
	algorithm: DGPM2
	checkpoint_freq: None
	data_dir: /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/domainbed/data/
	dataset: TerraIncognita
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 0
	output_dir: /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/domainbed/run_sweep/reported_test_DGPM2_TerraIncognita_manyvalues_variance/014a3a988a15cadb0fab290ef4d7e80e
	save_model_every_checkpoint: False
	seed: 852730742
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [1]
	trial_seed: 1
	uda_holdout_fraction: 0
HParams:
	batch_size: 40
	class_balanced: False
	data_augmentation: True
	dgpm_lambda: 5.0
	dgpm_lr: 1.5e-05
	dgpm_penalty_anneal_iters: 1500
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.0
	variance_weight: 0.04
	weight_decay: 0.0
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
wandb: Currently logged in as: ktoan271199 (nktoan271199). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/wandb/run-20230802_011158-8l3ip9ct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-water-1329
wandb:  View project at https://wandb.ai/nktoan271199/risk_distribution_matching_PACS
wandb:  View run at https://wandb.ai/nktoan271199/risk_distribution_matching_PACS/runs/8l3ip9ct
dgpm_lambda   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         erm_loss      matching_pen  mem_gb        step          step_time     total_loss    variance_pen 
5.0000000000  0.2098602689  0.1814345992  0.4630889716  0.4560862866  0.1914357683  0.2166246851  0.2175483323  0.2304421769  0.0000000000  2.3951787949  0.0890007019  9.8736286163  0             2.0656762123  2.3951787949  0.2036043406 
5.0000000000  0.8924334300  0.8544303797  0.3788676338  0.3816127375  0.7660579345  0.7670025189  0.7459103463  0.7134353741  3.7783375315  0.8456854672  0.1197559547  10.055573940  300           0.5321564054  0.8456854672  2.1111766610 
5.0000000000  0.9111521223  0.8945147679  0.3223777122  0.3127889060  0.8076196474  0.7884130982  0.8039090716  0.7704081633  7.5566750630  0.4894444778  0.0912209129  10.055573940  600           0.5329245989  0.4894444778  1.8024215140 
5.0000000000  0.9182704983  0.8955696203  0.4566696623  0.4514637904  0.8428841310  0.8123425693  0.8158062460  0.7653061224  11.335012594  0.4047268437  0.0842431959  10.055573940  900           0.5298205487  0.4047268437  1.6129549261 
5.0000000000  0.9390983390  0.9082278481  0.4657850815  0.4699537750  0.8592569270  0.8413098237  0.8328022095  0.7857142857  15.113350125  0.3408993483  0.0712837187  10.055573940  1200          0.5294188499  0.3408993483  1.4097595158 
5.0000000000  0.9472712892  0.9240506329  0.3972268584  0.4052388290  0.8948362720  0.8513853904  0.8621202464  0.8061224490  18.891687657  0.2845977781  0.0705195808  10.055573940  1500          0.5272095625  0.2851982115  1.2423827677 
5.0000000000  0.9071974690  0.8850210970  0.4493516498  0.4576271186  0.8718513854  0.8425692695  0.8421499894  0.7882653061  22.670025188  0.3408478612  0.0454338487  10.056657314  1800          0.5292101971  0.5680171106  1.9364056676 
5.0000000000  0.8718692328  0.8649789030  0.3990242650  0.3990755008  0.8079345088  0.7544080605  0.8410877417  0.7840136054  26.448362720  0.3535297464  0.0411156782  10.056657314  2100          0.5281154410  0.5591081430  1.8859777652 
5.0000000000  0.9267070920  0.9103375527  0.4515342149  0.4571135080  0.8441435768  0.8198992443  0.8457616316  0.7806122449  30.226700251  0.3631786291  0.0418239276  10.056657314  2400          0.5258325187  0.5722982734  2.0220447104 
5.0000000000  0.9259161613  0.9018987342  0.4212350751  0.4293785311  0.8740554156  0.8476070529  0.8559592097  0.7967687075  34.005037783  0.3419329058  0.0397507254  10.056657314  2700          0.5193159540  0.5406865384  1.9121703518 
5.0000000000  0.9253888742  0.8934599156  0.4245731159  0.4304057524  0.8932619647  0.8576826196  0.8646696410  0.7976190476  37.783375314  0.3377850339  0.0402256266  10.056657314  3000          0.5186002636  0.5389131723  1.9787697740 
5.0000000000  0.9095702610  0.8945147679  0.4763127487  0.4853620955  0.8712216625  0.8614609572  0.8523475675  0.8069727891  41.561712846  0.3245137177  0.0388716825  10.056657314  3300          0.5181583818  0.5188721338  1.9309426018 
5.0000000000  0.9443712101  0.9113924051  0.4415200924  0.4478685157  0.8838161209  0.8463476071  0.8640322923  0.8018707483  45.340050377  0.3371718994  0.0387667370  10.056657314  3600          0.5199546464  0.5310055901  1.7837634337 
5.0000000000  0.9443712101  0.9198312236  0.4657850815  0.4802259887  0.8772040302  0.8274559194  0.8746547695  0.8256802721  49.118387909  0.3086888329  0.0365218480  10.056657314  3900          0.5195167851  0.4912980779  1.6846063171 
5.0000000000  0.9354073293  0.9156118143  0.4173834895  0.4252696456  0.8976700252  0.8539042821  0.8718929254  0.8265306122  52.896725440  0.3451598095  0.0397498703  10.056657314  4200          0.5193203179  0.5439091655  1.9886037006 
5.0000000000  0.9256525178  0.9029535865  0.4191808961  0.4309193631  0.8929471033  0.8387909320  0.8784788613  0.8129251701  56.675062972  0.3366867489  0.0372778543  10.056657314  4500          0.5166302546  0.5230760240  1.9141991419 
5.0000000000  0.9164249934  0.9071729958  0.4141738349  0.4262968670  0.8913727960  0.8576826196  0.8674314850  0.8248299320  60.453400503  0.3188805712  0.0369551913  10.056657314  4800          0.5175646377  0.5036565321  1.9332931678 
5.0000000000  0.9430529924  0.9156118143  0.4019771473  0.4031843862  0.8570528967  0.8098236776  0.8772041640  0.8316326531  62.972292191  0.3310549416  0.0385626411  10.056657314  5000          0.5211874890  0.5238681526  1.9254997468 
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb:      dgpm_lambda 5.0
wandb:         erm_loss 0.27425
wandb: matching_penalty 0.01792
wandb:       total_loss 0.36384
wandb:     update_count 5001
wandb: variance_penalty 1.48665
wandb: 
wandb:  View run comic-water-1329 at: https://wandb.ai/nktoan271199/risk_distribution_matching_PACS/runs/8l3ip9ct
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230802_011158-8l3ip9ct/logs
