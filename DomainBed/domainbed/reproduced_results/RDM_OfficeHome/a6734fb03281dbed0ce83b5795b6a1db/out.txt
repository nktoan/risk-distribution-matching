Environment:
	Python: 3.11.2
	PyTorch: 2.0.0+cu117
	Torchvision: 0.15.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.2
	PIL: 9.5.0
Args:
	algorithm: DGPM2
	checkpoint_freq: None
	data_dir: /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/domainbed/data/
	dataset: OfficeHome
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 1
	output_dir: /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/domainbed/run_sweep/reported_test3Aug_DGPM2_OfficeHome_lowerweight_matching/a6734fb03281dbed0ce83b5795b6a1db
	save_model_every_checkpoint: False
	seed: 583124323
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 96
	class_balanced: False
	data_augmentation: True
	dgpm_lambda: 0.1518462950381929
	dgpm_lr: 8.266310922728087e-06
	dgpm_penalty_anneal_iters: 2287
	lr: 4.4049700015373634e-05
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.0
	variance_weight: 0.0
	weight_decay: 9.743107780992378e-07
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
wandb: Currently logged in as: ktoan271199 (nktoan271199). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/wandb/run-20230803_155308-fak8njtt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sponge-1543
wandb:  View project at https://wandb.ai/nktoan271199/risk_distribution_matching_PACS
wandb:  View run at https://wandb.ai/nktoan271199/risk_distribution_matching_PACS/runs/fak8njtt
dgpm_lambda   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         erm_loss      matching_pen  mem_gb        step          step_time     total_loss    variance_pen 
0.1518462950  0.0149330587  0.0123711340  0.0168957617  0.0171821306  0.0320945946  0.0225479143  0.0166379805  0.0172215844  0.0000000000  4.2657704353  0.0264644623  23.549080848  0             2.9385960102  4.2657704353  0.2392902076 
0.1518462950  0.9685890834  0.7319587629  0.9266895762  0.7227949599  0.9614301802  0.8523111612  0.7587492828  0.7451205511  14.830072090  0.6877764465  0.0430443319  23.723642349  300           1.4056555645  0.6877764465  2.5696009874 
0.1518462950  0.9860968074  0.7257731959  0.9616265750  0.7640320733  0.9842342342  0.8635851184  0.7504302926  0.7646383467  29.660144181  0.1091477518  0.0214558983  23.723642349  600           1.4081165862  0.1091477518  0.7076327276 
0.1518462950  0.9886714727  0.7278350515  0.9722222222  0.7468499427  0.9898648649  0.8759864713  0.7426850258  0.7703788749  44.490216271  0.0607112145  0.0115560055  23.723642349  900           1.3984522398  0.0607112145  0.4317176548 
0.1518462950  0.9902162719  0.7113402062  0.9733676976  0.7766323024  0.9890202703  0.8556933484  0.7432587493  0.7359357061  59.320288362  0.0493435424  0.0087732093  23.723642349  1200          1.3958076652  0.0493435424  0.3357597055 
0.1518462950  0.9922760041  0.7319587629  0.9810996564  0.7686139748  0.9901463964  0.8737316798  0.7492828457  0.7451205511  74.150360453  0.0446491842  0.0089194520  23.723642349  1500          1.3964275750  0.0446491842  0.3472591852 
0.1518462950  0.9897013388  0.7175257732  0.9699312715  0.7789232532  0.9881756757  0.8714768884  0.7429718876  0.7428243398  88.980432543  0.0393646789  0.0064776198  23.723642349  1800          1.3905728801  0.0393646789  0.2845262044 
0.1518462950  0.9912461380  0.7360824742  0.9802405498  0.7686139748  0.9918355856  0.8782412627  0.7601835915  0.7554535017  103.81050463  0.0360045539  0.0067918968  23.723642349  2100          1.3868747528  0.0360045539  0.2465087759 
0.1518462950  0.9948506694  0.7463917526  0.9859679267  0.8087056128  0.9966216216  0.8895152198  0.7751004016  0.7646383467  118.64057672  0.0261160726  0.0042004744  23.723642349  2400          1.3937579298  0.0263076163  0.1665074203 
0.1518462950  0.9958805355  0.7505154639  0.9871134021  0.8006872852  0.9971846847  0.8850056370  0.7808376363  0.7738231917  133.47064881  0.0148753821  0.0024380366  23.723642349  2700          1.3937056263  0.0152455890  0.0936253048 
0.1518462950  0.9958805355  0.7525773196  0.9876861397  0.7972508591  0.9969031532  0.8985343856  0.7742398164  0.7657864524  148.30072090  0.0144330487  0.0025226879  23.723642349  3000          1.3950066415  0.0148161095  0.0763012749 
0.1518462950  0.9963954686  0.7711340206  0.9868270332  0.8075601375  0.9977477477  0.8928974070  0.7742398164  0.7818599311  163.13079299  0.0131456022  0.0022815832  23.723642349  3300          1.3966546845  0.0134920521  0.0645792871 
0.1518462950  0.9938208033  0.7711340206  0.9876861397  0.7777777778  0.9963400901  0.8883878241  0.7785427424  0.7910447761  177.96086508  0.0124153891  0.0019706662  23.723642349  3600          1.3997500769  0.0127146274  0.0665124925 
0.1518462950  0.9963954686  0.7567010309  0.9894043528  0.8006872852  0.9969031532  0.8872604284  0.7719449225  0.7761194030  192.79093717  0.0124395541  0.0021878751  23.723642349  3900          1.3955670134  0.0127717749  0.0594530155 
0.1518462950  0.9974253347  0.7443298969  0.9882588774  0.7823596793  0.9971846847  0.8917700113  0.7710843373  0.7807118255  207.62100926  0.0125452578  0.0019469420  23.723642349  4200          1.3922735174  0.0128408937  0.0739782603 
0.1518462950  0.9974253347  0.7463917526  0.9879725086  0.7938144330  0.9960585586  0.8951521984  0.7707974756  0.7646383467  222.45108135  0.0128773757  0.0021657213  23.723642349  4500          1.3935207939  0.0132062325  0.0660412829 
0.1518462950  0.9958805355  0.7628865979  0.9882588774  0.7949599084  0.9974662162  0.9007891770  0.7722317843  0.7749712974  237.28115345  0.0118454254  0.0020747598  23.723642349  4800          1.4011836116  0.0121604700  0.0562424392 
0.1518462950  0.9979402678  0.7443298969  0.9879725086  0.7846506300  0.9954954955  0.8793686584  0.7659208262  0.7566016073  247.16786817  0.0128505807  0.0019693089  23.723642349  5000          1.4129805183  0.0131496129  0.0661089143 
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: \ 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: | 0.010 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: / 0.010 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: - 0.018 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: \ 0.018 MB of 0.018 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb:      dgpm_lambda 0.15185
wandb:         erm_loss 0.00108
wandb: matching_penalty 0.00014
wandb:       total_loss 0.0011
wandb:     update_count 5001
wandb: variance_penalty 0.00018
wandb: 
wandb:  View run vibrant-sponge-1543 at: https://wandb.ai/nktoan271199/risk_distribution_matching_PACS/runs/fak8njtt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230803_155308-fak8njtt/logs
