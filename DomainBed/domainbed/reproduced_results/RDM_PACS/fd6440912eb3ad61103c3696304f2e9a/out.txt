Environment:
	Python: 3.11.2
	PyTorch: 2.0.0+cu117
	Torchvision: 0.15.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.2
	PIL: 9.5.0
Args:
	algorithm: DGPM2
	checkpoint_freq: None
	data_dir: /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 4
	output_dir: /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/domainbed/run_sweep/reported_final2_PACS/fd6440912eb3ad61103c3696304f2e9a
	save_model_every_checkpoint: False
	seed: 1534492033
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [0]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	batch_size: 78
	class_balanced: False
	data_augmentation: True
	dgpm_lambda: 9.777247330943908
	dgpm_lr: 1.0436584129189127e-05
	dgpm_penalty_anneal_iters: 1127
	lr: 4.629441691482996e-05
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.0
	variance_weight: 0.0025138108552499494
	weight_decay: 3.989172001355785e-08
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
wandb: Currently logged in as: ktoan271199 (nktoan271199). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/wandb/run-20230729_015426-bg3xfy3n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-cosmos-614
wandb:  View project at https://wandb.ai/nktoan271199/risk_distribution_matching_PACS
wandb:  View run at https://wandb.ai/nktoan271199/risk_distribution_matching_PACS/runs/bg3xfy3n
dgpm_lambda   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         erm_loss      matching_pen  mem_gb        step          step_time     total_loss    variance_pen 
9.7772473309  0.1647345943  0.1662591687  0.2718550107  0.2756410256  0.2702095808  0.2395209581  0.2474554707  0.2280254777  0.0000000000  2.0156352520  0.0431957245  19.151410579  0             2.6054279804  2.0156352520  0.1294067800 
9.7772473309  0.8468578401  0.8459657702  0.9925373134  0.9487179487  0.9977544910  0.9790419162  0.9685114504  0.9464968153  17.514970059  0.1459616483  0.0391287804  19.328848362  300           0.8431465936  0.1459616483  0.5276796438 
9.7772473309  0.8517388652  0.8361858191  0.9920042644  0.9529914530  0.9970059880  0.9790419162  0.9939567430  0.9630573248  35.029940119  0.0216960533  0.0056415844  19.328848362  600           0.8415125648  0.0216960533  0.1507622235 
9.7772473309  0.8328248932  0.7995110024  0.9984008529  0.9722222222  1.0000000000  0.9730538922  0.9971374046  0.9541401274  52.544910179  0.0151774987  0.0032214165  19.328848362  900           0.8421365857  0.0151774987  0.1274752607 
9.7772473309  0.8419768151  0.8264058680  1.0000000000  0.9636752137  1.0000000000  0.9760479042  0.9993638677  0.9630573248  70.059880239  0.0092531603  0.0017216206  19.330740451  1200          0.8423324450  0.0114652584  0.0840716099 
9.7772473309  0.8791946309  0.8728606357  0.9989339019  0.9722222222  1.0000000000  0.9850299401  0.9993638677  0.9668789809  87.574850299  0.0025452267  0.0003126589  19.330740451  1500          0.8444678195  0.0057195003  0.0466740728 
9.7772473309  0.8608907871  0.8386308068  0.9989339019  0.9594017094  0.9985029940  0.9790419162  0.9990458015  0.9554140127  105.08982035  0.0031015787  0.0003281371  19.330740451  1800          0.8434025923  0.0064426670  0.0528325271 
9.7772473309  0.8798047590  0.8801955990  1.0000000000  0.9679487179  1.0000000000  0.9850299401  1.0000000000  0.9617834395  122.60479041  0.0016484053  0.0001815859  19.330740451  2100          0.8435998734  0.0034928355  0.0274560894 
9.7772473309  0.8981086028  0.8899755501  0.9978678038  0.9658119658  1.0000000000  0.9790419162  0.9977735369  0.9630573248  140.11976047  0.0031400144  0.0003964615  19.330740451  2400          0.8425121188  0.0071191676  0.0409144069 
9.7772473309  0.8145210494  0.8312958435  0.9984008529  0.9764957265  1.0000000000  0.9880239521  0.9942748092  0.9414012739  157.63473053  0.0019144189  0.0002219009  19.330740451  2700          0.8448459260  0.0041631416  0.0314829958 
9.7772473309  0.8151311775  0.8459657702  0.9994669510  0.9444444444  0.9940119760  0.9760479042  0.9980916031  0.9566878981  175.14970059  0.0073842843  0.0006032817  19.330740451  3000          0.8416006676  0.0136073693  0.1291469575 
9.7772473309  0.8688224527  0.8801955990  1.0000000000  0.9700854701  1.0000000000  0.9850299401  0.9987277354  0.9656050955  192.66467065  0.0021040677  0.0002213860  19.330740451  3300          0.8451424996  0.0043932810  0.0495932847 
9.7772473309  0.8633312996  0.8679706601  1.0000000000  0.9658119658  1.0000000000  0.9760479042  0.9993638677  0.9668789809  210.17964071  0.0007374288  0.0000780646  19.330740451  3600          0.8462457037  0.0015406607  0.0159021356 
9.7772473309  0.8712629652  0.8777506112  1.0000000000  0.9594017094  1.0000000000  0.9820359281  1.0000000000  0.9528662420  227.69461077  0.0006419034  0.0000669352  19.330740451  3900          0.8466172783  0.0013234724  0.0107910928 
9.7772473309  0.8804148871  0.8777506112  1.0000000000  0.9636752137  1.0000000000  0.9760479042  0.9990458015  0.9630573248  245.20958083  0.0003682501  0.0000541751  19.330740451  4200          0.8432071487  0.0009053403  0.0029466359 
9.7772473309  0.8737034777  0.8581907090  0.9989339019  0.9465811966  1.0000000000  0.9820359281  0.9977735369  0.9566878981  262.72455089  0.0009275472  0.0000969092  19.330740451  4500          0.8453394111  0.0018988927  0.0094837007 
9.7772473309  0.8688224527  0.8704156479  0.9994669510  0.9658119658  1.0000000000  0.9790419162  0.9990458015  0.9579617834  280.23952095  0.0014606022  0.0001546764  19.330740451  4800          0.8444949222  0.0030448243  0.0286068636 
9.7772473309  0.8547895058  0.8655256724  1.0000000000  0.9722222222  1.0000000000  0.9850299401  0.9996819338  0.9643312102  291.91616766  0.0007580387  0.0000898075  19.330740451  5000          0.8426374567  0.0016704152  0.0136470935 
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb:      dgpm_lambda 9.77725
wandb:         erm_loss 0.0
wandb: matching_penalty 0.0
wandb:       total_loss 0.0
wandb:     update_count 5001
wandb: variance_penalty 0.0
wandb: 
wandb:  View run breezy-cosmos-614 at: https://wandb.ai/nktoan271199/risk_distribution_matching_PACS/runs/bg3xfy3n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230729_015426-bg3xfy3n/logs
