Environment:
	Python: 3.11.2
	PyTorch: 2.0.0+cu117
	Torchvision: 0.15.1+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.24.2
	PIL: 9.5.0
Args:
	algorithm: DGPM2
	checkpoint_freq: None
	data_dir: /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: None
	hparams_seed: 2
	output_dir: /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/domainbed/run_sweep/reported_final2_PACS/930ffde016e81af2ec782702fe7f6049
	save_model_every_checkpoint: False
	seed: 148046983
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 1
	uda_holdout_fraction: 0
HParams:
	batch_size: 79
	class_balanced: False
	data_augmentation: True
	dgpm_lambda: 2.941221173798578
	dgpm_lr: 1.2968485016185973e-05
	dgpm_penalty_anneal_iters: 2234
	lr: 9.478256868029222e-05
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.0
	variance_weight: 0.0011782602840881265
	weight_decay: 2.5806729649878144e-08
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/s222165627/.conda/envs/domainbed/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
wandb: Currently logged in as: ktoan271199 (nktoan271199). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /home/s222165627/causal_optimisation_dg/quantile_rm/DomainBed/wandb/run-20230729_010708-gtd67xn2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-morning-596
wandb:  View project at https://wandb.ai/nktoan271199/risk_distribution_matching_PACS
wandb:  View run at https://wandb.ai/nktoan271199/risk_distribution_matching_PACS/runs/gtd67xn2
dgpm_lambda   env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         erm_loss      matching_pen  mem_gb        step          step_time     total_loss    variance_pen 
2.9412211738  0.3892617450  0.3960880196  0.2004264392  0.1752136752  0.5194610778  0.5329341317  0.0807888041  0.0675159236  0.0000000000  1.9752330780  0.0421743393  19.391904354  0             1.9190201759  1.9752330780  0.1466155648 
2.9412211738  0.9816961562  0.9339853301  0.9920042644  0.9487179487  0.9955089820  0.9760479042  0.7519083969  0.7541401274  17.739520958  0.1345839441  0.0252556992  19.567474842  300           0.7578909397  0.1345839441  0.5673233372 
2.9412211738  0.9938987187  0.9584352078  0.9946695096  0.9572649573  0.9992514970  0.9760479042  0.7604961832  0.7477707006  35.479041916  0.0298079383  0.0049860032  19.567474842  600           0.7567793655  0.0298079383  0.2232694840 
2.9412211738  0.9963392312  0.9290953545  0.9968017058  0.9487179487  0.9985029940  0.9790419162  0.7942111959  0.7923566879  53.218562874  0.0205714962  0.0031461048  19.567474842  900           0.7568607434  0.0205714962  0.1739697134 
2.9412211738  0.9859670531  0.9290953545  0.9936034115  0.9316239316  1.0000000000  0.9730538922  0.7554071247  0.7261146497  70.958083832  0.0142040104  0.0021219317  19.567474842  1200          0.7557273221  0.0142040104  0.1316929877 
2.9412211738  0.9920683344  0.9388753056  0.9952025586  0.9465811966  0.9977544910  0.9790419162  0.7388676845  0.7426751592  88.697604790  0.0172310344  0.0022182814  19.567474842  1500          0.7579275258  0.0172310344  0.1751008846 
2.9412211738  0.9975594875  0.9266503667  0.9978678038  0.9444444444  0.9985029940  0.9760479042  0.7302798982  0.7108280255  106.43712574  0.0139677611  0.0021292909  19.567474842  1800          0.7564797759  0.0139677611  0.1511743066 
2.9412211738  0.9993898719  0.9290953545  0.9946695096  0.9508547009  0.9970059880  0.9850299401  0.7751272265  0.7808917197  124.17664670  0.0119605536  0.0015958659  19.567474842  2100          0.7568022283  0.0119605536  0.1171053111 
2.9412211738  0.9987797437  0.9388753056  0.9994669510  0.9594017094  1.0000000000  0.9880239521  0.7856234097  0.7656050955  141.91616766  0.0045158650  0.0005915769  19.567474842  2400          0.7551760944  0.0048344195  0.0446756490 
2.9412211738  1.0000000000  0.9535452323  1.0000000000  0.9615384615  1.0000000000  0.9820359281  0.8323791349  0.8242038217  159.65568862  0.0008813312  0.0001133124  19.567474842  2700          0.7612888821  0.0012297750  0.0128722580 
2.9412211738  1.0000000000  0.9462102689  0.9994669510  0.9615384615  1.0000000000  0.9850299401  0.8113867684  0.8216560510  177.39520958  0.0012429814  0.0001489003  19.567474842  3000          0.7601396839  0.0016970155  0.0136517230 
2.9412211738  0.9993898719  0.9437652812  1.0000000000  0.9636752137  1.0000000000  0.9790419162  0.8091603053  0.8254777070  195.13473053  0.0005679094  0.0000825691  19.567474842  3300          0.7583083073  0.0008158231  0.0042942079 
2.9412211738  0.9993898719  0.9437652812  1.0000000000  0.9594017094  1.0000000000  0.9730538922  0.7611323155  0.7490445860  212.87425149  0.0009266605  0.0000997798  19.567474842  3600          0.7606942225  0.0012398295  0.0167150317 
2.9412211738  0.9993898719  0.9559902200  1.0000000000  0.9615384615  1.0000000000  0.9790419162  0.8117048346  0.7974522293  230.61377245  0.0004143410  0.0000438436  19.567474842  3900          0.7604709482  0.0005511538  0.0066700966 
2.9412211738  0.9993898719  0.9339853301  1.0000000000  0.9615384615  1.0000000000  0.9880239521  0.7961195929  0.7974522293  248.35329341  0.0011300083  0.0001057339  19.567474842  4200          0.7587006863  0.0014690495  0.0238101381 
2.9412211738  1.0000000000  0.9535452323  1.0000000000  0.9636752137  1.0000000000  0.9850299401  0.8018447837  0.7910828025  266.09281437  0.0001330809  0.0000250880  19.567474842  4500          0.7598534155  0.0002076209  0.0006371269 
2.9412211738  1.0000000000  0.9486552567  1.0000000000  0.9658119658  1.0000000000  0.9910179641  0.8355597964  0.8292993631  283.83233532  0.0004189105  0.0000495911  19.567474842  4800          0.7609298611  0.0005706009  0.0049497365 
2.9412211738  1.0000000000  0.9486552567  0.9989339019  0.9572649573  1.0000000000  0.9820359281  0.7547709924  0.7439490446  295.65868263  0.0023476653  0.0001817942  19.567474842  5000          0.7625872910  0.0029342854  0.0440677934 
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb:      dgpm_lambda 2.94122
wandb:         erm_loss 9e-05
wandb: matching_penalty 4e-05
wandb:       total_loss 0.00021
wandb:     update_count 5001
wandb: variance_penalty 0.0
wandb: 
wandb:  View run logical-morning-596 at: https://wandb.ai/nktoan271199/risk_distribution_matching_PACS/runs/gtd67xn2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230729_010708-gtd67xn2/logs
